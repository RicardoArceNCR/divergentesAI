from app.services.scraper_extractor import extraer_contenido
from app.nlp.clasificador import clasificar_texto
from app.nlp.entidades import extraer_entidades
from app.logic.summary import resumir

def procesar_articulo_completo(url: str) -> dict:
    """
    Toma una URL y devuelve un art√≠culo con metadatos, resumen, categor√≠as, entidades y logs de validaci√≥n.
    """
    print(f"üîç Procesando: {url}")
    datos = extraer_contenido(url)

    texto = datos.get("texto", "").strip()
    if not texto or len(texto) < 30:
        print(f"‚ùå Texto vac√≠o o demasiado corto para: {url}")
        return {
            "url": url,
            "error": "Texto vac√≠o o muy corto",
            "datos_raw": datos
        }

    resultado = {
        "titulo": datos.get("titulo", "Sin t√≠tulo"),
        "subtitulo": datos.get("subtitulo", ""),
        "url": url,
        "autor": datos.get("autor", ""),
        "fecha": datos.get("fecha", ""),
        "texto": texto
    }

    try:
        resumen = resumir(texto)
        resultado["resumen"] = resumen if resumen != "string" else ""
        print(f"üìù Resumen generado: {resumen[:80]}...")
    except Exception as e:
        resultado["resumen"] = ""
        print(f"‚ö†Ô∏è Error al generar resumen: {e}")

    try:
        categorias = clasificar_texto(texto)
        resultado["categorias"] = categorias
        print(f"üìä Categor√≠as: {categorias}")
    except Exception as e:
        resultado["categorias"] = {}
        print(f"‚ö†Ô∏è Error al clasificar texto: {e}")

    try:
        entidades = extraer_entidades(texto)
        resultado["entidades"] = entidades
        print(f"üè∑Ô∏è Entidades: {entidades}")
    except Exception as e:
        resultado["entidades"] = {}
        print(f"‚ö†Ô∏è Error al extraer entidades: {e}")

    return resultado
